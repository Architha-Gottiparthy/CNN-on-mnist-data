{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Copy of CNN on MNIST in Python With Keras.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgQuQ7cp9BnZ",
        "colab_type": "text"
      },
      "source": [
        "## MLP vs CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbTbKgs99Bni",
        "colab_type": "text"
      },
      "source": [
        "##### Keras model module\n",
        "\n",
        "    Import the Sequential model type from Keras. This is an interface to build a linear stack of neural network layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibPYiu_D9Bnk",
        "colab_type": "code",
        "outputId": "9d170377-d02a-4e94-9b3e-80887714d28c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "from keras.models import Sequential"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfGFuW109Bny",
        "colab_type": "text"
      },
      "source": [
        "##### Keras core layers\n",
        "    \n",
        "    Import the \"core\" layers from Keras. These are the layers that are used in almost any neural network:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_gQhghr9Bnz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import core"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDkU0fsY9BoL",
        "colab_type": "text"
      },
      "source": [
        "##### Keras CNN layers\n",
        "\n",
        "     Import the CNN layers from Keras. These are the convolutional layers that will help us efficiently train on image data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvPDnyeh9BoU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import convolutional, pooling"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QZj-p5s9Bog",
        "colab_type": "text"
      },
      "source": [
        "#### Load image data from MNIST.\n",
        "\n",
        "    MNIST database of handwritten digits\n",
        "\n",
        "    Dataset of 60,000 28x28 grayscale images of the 10 digits, along with a test set of 10,000 images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36lAA6O69Boh",
        "colab_type": "code",
        "outputId": "574d7770-1a6b-4569-d8f4-ee313b7c03c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "from keras.datasets import fashion_mnist\n",
        " \n",
        "# Load pre-shuffled MNIST data into train and test sets\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 8us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 4s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QymDqpGS9Bom",
        "colab_type": "text"
      },
      "source": [
        "Returns:\n",
        "\n",
        "    2 tuples:\n",
        "            x_train, x_test: uint8 array of grayscale image data with shape (num_samples, 28, 28).\n",
        "            y_train, y_test: uint8 array of digit labels (integers in range 0-9) with shape (num_samples,).\n",
        "\n",
        "Arguments:\n",
        "\n",
        "    path: if you do not have the index file locally (at '~/.keras/datasets/' + path), it will be downloaded to this location.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpkQmkv29Bor",
        "colab_type": "text"
      },
      "source": [
        "Look at the shape of the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuSgqKzM9Bo8",
        "colab_type": "code",
        "outputId": "ab8080c0-0961-4f24-eff1-71590ee16b4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print (X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQBheJRs9BpD",
        "colab_type": "text"
      },
      "source": [
        "## MLP for MNIST Digit Recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbSa0xGY9BpE",
        "colab_type": "text"
      },
      "source": [
        "### Prepare MNIST Data for MLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACqrsB6N9BpG",
        "colab_type": "text"
      },
      "source": [
        "Convert our data type to float32 and normalize our data values to the range [0, 1]\n",
        "\n",
        "Note: Max value X_train/X_test can take is 255, so it is divided by 255"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2bCRysj9BpH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIv9g7OT9Bpl",
        "colab_type": "text"
      },
      "source": [
        "#### Preprocess class labels for Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEtZDioA9Bpm",
        "colab_type": "text"
      },
      "source": [
        "Look at the shape of our class label data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcDEpI2y9Bpn",
        "colab_type": "code",
        "outputId": "fc76a06f-7673-412f-9938-7aa9f3820afc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print (y_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfK58AX19Bpw",
        "colab_type": "text"
      },
      "source": [
        "We should have 10 different classes, one for each digit, but it looks like we only have a 1-dimensional array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YhJJXJh9Bpx",
        "colab_type": "code",
        "outputId": "46dd50a9-c196-4d94-b61d-dbb7b474fe10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print (y_train[:10])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[9 0 0 3 0 2 7 2 5 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "RpdMzxQt9Bpz",
        "colab_type": "text"
      },
      "source": [
        "##### Convert 1-dimensional class arrays to 10-dimensional class matrices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GenFtct-9Bp0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import to_categorical"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zFIBzx29Bp3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_train = to_categorical(y_train, 10)\n",
        "Y_test = to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnxRpvv49Bp6",
        "colab_type": "text"
      },
      "source": [
        "Take another look:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4L57mamG9Bp8",
        "colab_type": "code",
        "outputId": "acbafa56-ac8f-499e-fea5-866272a6e535",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print (Y_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iP0v2Ty19BqB",
        "colab_type": "code",
        "outputId": "461cb1c3-9aa0-49b5-f97d-83dde5e38cec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print (Y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. ... 0. 0. 1.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5n4hhLTb9BqE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Same number of samples, but flatten the 28, 28 to 28*28 (784)\n",
        "\n",
        "X_train_mlp = X_train.reshape(X_train.shape[0], X_train.shape[1] * X_train.shape[2])\n",
        "\n",
        "X_test_mlp = X_test.reshape(X_test.shape[0], X_test.shape[1] * X_test.shape[2])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tovPyiy09BqG",
        "colab_type": "code",
        "outputId": "ca36885e-e3c6-4340-dac2-de87edf96cac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print (X_train_mlp.shape, y_train.shape, X_test.shape, y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784) (60000,) (10000, 28, 28) (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuCCSHui9BqJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.core import Activation, Dense, Dropout\n",
        "from keras.layers.normalization import BatchNormalization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMe1fsSG9BqQ",
        "colab_type": "code",
        "outputId": "637105c0-9736-49f1-9198-02dc6bec663f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(512, input_shape=(784,)))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(256))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(10))\n",
        "model.add(Activation(\"softmax\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbdB58lu9BqV",
        "colab_type": "code",
        "outputId": "f0aee042-7aec-44e6-d5c5-58d37036fbe6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                2570      \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 538,890\n",
            "Trainable params: 537,354\n",
            "Non-trainable params: 1,536\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtT9iWL79BqZ",
        "colab_type": "code",
        "outputId": "171add51-5742-40cc-c2fd-0e91e4aef377",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "PYqgQGfw9Bqc",
        "colab_type": "code",
        "outputId": "3357a5dd-2de1-4323-c5ea-e167ed9c0afb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "history = model.fit(X_train_mlp, Y_train, validation_split = 0.2,\n",
        "                    batch_size = 48000, epochs = 40)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/40\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "48000/48000 [==============================] - 10s 207us/step - loss: 3.1294 - acc: 0.0904 - val_loss: 1.3226 - val_acc: 0.5726\n",
            "Epoch 2/40\n",
            "48000/48000 [==============================] - 0s 4us/step - loss: 1.4681 - acc: 0.5157 - val_loss: 0.9059 - val_acc: 0.6883\n",
            "Epoch 3/40\n",
            "48000/48000 [==============================] - 0s 3us/step - loss: 1.0252 - acc: 0.6576 - val_loss: 0.8494 - val_acc: 0.7132\n",
            "Epoch 4/40\n",
            "48000/48000 [==============================] - 0s 3us/step - loss: 0.8761 - acc: 0.7039 - val_loss: 0.7758 - val_acc: 0.7414\n",
            "Epoch 5/40\n",
            "48000/48000 [==============================] - 0s 3us/step - loss: 0.7828 - acc: 0.7325 - val_loss: 0.6835 - val_acc: 0.7690\n",
            "Epoch 6/40\n",
            "48000/48000 [==============================] - 0s 3us/step - loss: 0.7277 - acc: 0.7496 - val_loss: 0.6180 - val_acc: 0.7895\n",
            "Epoch 7/40\n",
            "48000/48000 [==============================] - 0s 3us/step - loss: 0.6814 - acc: 0.7609 - val_loss: 0.5846 - val_acc: 0.8021\n",
            "Epoch 8/40\n",
            "48000/48000 [==============================] - 0s 3us/step - loss: 0.6560 - acc: 0.7698 - val_loss: 0.5649 - val_acc: 0.8089\n",
            "Epoch 9/40\n",
            "48000/48000 [==============================] - 0s 3us/step - loss: 0.6270 - acc: 0.7787 - val_loss: 0.5495 - val_acc: 0.8135\n",
            "Epoch 10/40\n",
            "48000/48000 [==============================] - 0s 3us/step - loss: 0.6065 - acc: 0.7876 - val_loss: 0.5351 - val_acc: 0.8167\n",
            "Epoch 11/40\n",
            "48000/48000 [==============================] - 0s 3us/step - loss: 0.5841 - acc: 0.7943 - val_loss: 0.5212 - val_acc: 0.8203\n",
            "Epoch 12/40\n",
            "48000/48000 [==============================] - 0s 3us/step - loss: 0.5648 - acc: 0.8006 - val_loss: 0.5071 - val_acc: 0.8251\n",
            "Epoch 13/40\n",
            "48000/48000 [==============================] - 0s 3us/step - loss: 0.5509 - acc: 0.8047 - val_loss: 0.4927 - val_acc: 0.8284\n",
            "Epoch 14/40\n",
            "48000/48000 [==============================] - 0s 3us/step - loss: 0.5367 - acc: 0.8109 - val_loss: 0.4806 - val_acc: 0.8316\n",
            "Epoch 15/40\n",
            "48000/48000 [==============================] - 0s 3us/step - loss: 0.5267 - acc: 0.8131 - val_loss: 0.4708 - val_acc: 0.8338\n",
            "Epoch 16/40\n",
            "48000/48000 [==============================] - 0s 3us/step - loss: 0.5153 - acc: 0.8177 - val_loss: 0.4613 - val_acc: 0.8367\n",
            "Epoch 17/40\n",
            "48000/48000 [==============================] - 0s 3us/step - loss: 0.5035 - acc: 0.8208 - val_loss: 0.4526 - val_acc: 0.8414\n",
            "Epoch 18/40\n",
            "48000/48000 [==============================] - 0s 3us/step - loss: 0.4911 - acc: 0.8270 - val_loss: 0.4463 - val_acc: 0.8412\n",
            "Epoch 19/40\n",
            "48000/48000 [==============================] - 0s 3us/step - loss: 0.4824 - acc: 0.8293 - val_loss: 0.4423 - val_acc: 0.8422\n",
            "Epoch 20/40\n",
            "48000/48000 [==============================] - 0s 3us/step - loss: 0.4746 - acc: 0.8292 - val_loss: 0.4383 - val_acc: 0.8432\n",
            "Epoch 21/40\n",
            "48000/48000 [==============================] - 0s 3us/step - loss: 0.4675 - acc: 0.8330 - val_loss: 0.4332 - val_acc: 0.8449\n",
            "Epoch 22/40\n",
            "48000/48000 [==============================] - 0s 3us/step - loss: 0.4601 - acc: 0.8355 - val_loss: 0.4279 - val_acc: 0.8475\n",
            "Epoch 23/40\n",
            "48000/48000 [==============================] - 0s 3us/step - loss: 0.4556 - acc: 0.8363 - val_loss: 0.4229 - val_acc: 0.8498\n",
            "Epoch 24/40\n",
            "48000/48000 [==============================] - 0s 3us/step - loss: 0.4468 - acc: 0.8401 - val_loss: 0.4188 - val_acc: 0.8510\n",
            "Epoch 25/40\n",
            "48000/48000 [==============================] - 0s 3us/step - loss: 0.4403 - acc: 0.8425 - val_loss: 0.4151 - val_acc: 0.8525\n",
            "Epoch 26/40\n",
            "48000/48000 [==============================] - 0s 3us/step - loss: 0.4353 - acc: 0.8449 - val_loss: 0.4117 - val_acc: 0.8543\n",
            "Epoch 27/40\n",
            "48000/48000 [==============================] - 0s 3us/step - loss: 0.4287 - acc: 0.8474 - val_loss: 0.4092 - val_acc: 0.8538\n",
            "Epoch 28/40\n",
            "48000/48000 [==============================] - 0s 3us/step - loss: 0.4231 - acc: 0.8487 - val_loss: 0.4063 - val_acc: 0.8547\n",
            "Epoch 29/40\n",
            "48000/48000 [==============================] - 0s 3us/step - loss: 0.4186 - acc: 0.8513 - val_loss: 0.4025 - val_acc: 0.8569\n",
            "Epoch 30/40\n",
            "48000/48000 [==============================] - 0s 3us/step - loss: 0.4117 - acc: 0.8530 - val_loss: 0.3980 - val_acc: 0.8577\n",
            "Epoch 31/40\n",
            "48000/48000 [==============================] - 0s 3us/step - loss: 0.4092 - acc: 0.8536 - val_loss: 0.3934 - val_acc: 0.8584\n",
            "Epoch 32/40\n",
            "48000/48000 [==============================] - 0s 3us/step - loss: 0.4071 - acc: 0.8546 - val_loss: 0.3893 - val_acc: 0.8595\n",
            "Epoch 33/40\n",
            "48000/48000 [==============================] - 0s 3us/step - loss: 0.4003 - acc: 0.8572 - val_loss: 0.3858 - val_acc: 0.8618\n",
            "Epoch 34/40\n",
            "48000/48000 [==============================] - 0s 3us/step - loss: 0.3944 - acc: 0.8580 - val_loss: 0.3831 - val_acc: 0.8630\n",
            "Epoch 35/40\n",
            "48000/48000 [==============================] - 0s 3us/step - loss: 0.3907 - acc: 0.8597 - val_loss: 0.3803 - val_acc: 0.8633\n",
            "Epoch 36/40\n",
            "48000/48000 [==============================] - 0s 3us/step - loss: 0.3879 - acc: 0.8607 - val_loss: 0.3772 - val_acc: 0.8643\n",
            "Epoch 37/40\n",
            "48000/48000 [==============================] - 0s 3us/step - loss: 0.3831 - acc: 0.8644 - val_loss: 0.3735 - val_acc: 0.8651\n",
            "Epoch 38/40\n",
            "48000/48000 [==============================] - 0s 3us/step - loss: 0.3773 - acc: 0.8654 - val_loss: 0.3698 - val_acc: 0.8672\n",
            "Epoch 39/40\n",
            "48000/48000 [==============================] - 0s 3us/step - loss: 0.3761 - acc: 0.8652 - val_loss: 0.3672 - val_acc: 0.8679\n",
            "Epoch 40/40\n",
            "48000/48000 [==============================] - 0s 3us/step - loss: 0.3701 - acc: 0.8663 - val_loss: 0.3656 - val_acc: 0.8689\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siqQTlSG9Bqj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ui_Rk2nO9Bqm",
        "colab_type": "code",
        "outputId": "fdfb132d-149f-4706-a185-8e5152ebe37a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "plt.plot(history.history[\"loss\"])\n",
        "plt.plot(history.history[\"val_loss\"])\n",
        "plt.title(\"Model Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3deZgddZ33/ff3bH16T2chWyfpRBgI\nSSAJMUFAQUAH0AFREHBF0YzoiNwz3s8wjo/L3PrczozDzSAqNygoDoKIsujA4BYGkDXBJGQBEkJi\n9nS27k7v5/T3+aOqOyed3pL06dPp+ryuq66qU1Xn9LfrSs6nf/Wr+pW5OyIiEl2xQhcgIiKFpSAQ\nEYk4BYGISMQpCEREIk5BICIScQoCEZGIUxCI9MHMaszMzSwxgH2vNbNnhqIukcGkIJARw8w2mlmb\nmY3ttv5P4Zd5TWEqO7JAERlqCgIZad4Erul8YWZzgJLClSMy/CkIZKT5CfCxnNcfB+7J3cHMKs3s\nHjOrNbNNZvZlM4uF2+Jm9m0z221mG4D39PDeH5rZdjPbambfMLP4sRRsZkVmdouZbQunW8ysKNw2\n1sx+bWb7zWyvmT2dU+vfhzU0mNlrZnbBsdQh0aUgkJHmeaDCzGaGX9BXA//RbZ/vAJXADOBcguD4\nRLjt08B7gXnAAuCKbu/9EZABTgz3eTfwqWOs+R+BM4G5wOnAQuDL4ba/A7YA44DxwJcAN7OTgb8B\n3uru5cBfAhuPsQ6JKAWBjESdrYJ3AWuBrZ0bcsLhH9y9wd03Av8GfDTc5YPALe6+2d33Av87573j\ngUuAG9290d13Af8n/Lxj8WHgn9x9l7vXAl/PqacdmAhMc/d2d3/agwHCskARcKqZJd19o7u/cYx1\nSEQpCGQk+gnwIeBaup0WAsYCSWBTzrpNwORweRKwudu2TtPC924PT9XsB/4vcMIx1juph3omhcv/\nCqwHfmNmG8zsJgB3Xw/cCHwN2GVm95vZJESOgoJARhx330TQaXwJ8Mtum3cT/JU9LWfdVA62GrYD\nU7pt67QZaAXGuvuocKpw91nHWPK2HurZFv4uDe7+d+4+A7gU+NvOvgB3/6m7nxO+14F/PsY6JKIU\nBDJSXQec7+6NuSvdPQs8AHzTzMrNbBrwtxzsR3gAuMHMqs2sCrgp573bgd8A/2ZmFWYWM7O3mNm5\nR1BXkZmlc6YYcB/wZTMbF176+pXOeszsvWZ2opkZUEdwSqjDzE42s/PDTuUWoBnoOMJjJAIoCGSE\ncvc33H1pL5s/DzQCG4BngJ8Cd4Xb7gSeAFYAL3N4i+JjQApYA+wDHiQ4hz9QBwi+tDun84FvAEuB\nlcAr4c/9Rrj/ScDvwvc9B3zP3ZcQ9A98i6CFs4Pg9NQ/HEEdIl1MD6YREYk2tQhERCJOQSAiEnEK\nAhGRiFMQiIhE3HE3EuLYsWO9pqam0GWIiBxXli1bttvdx/W07bgLgpqaGpYu7e2qQBER6YmZbept\nm04NiYhEnIJARCTiFAQiIhF33PUR9KS9vZ0tW7bQ0tJS6FJGjHQ6TXV1NclkstCliEiejYgg2LJl\nC+Xl5dTU1BCMzSXHwt3Zs2cPW7ZsYfr06YUuR0TybEScGmppaWHMmDEKgUFiZowZM0YtLJGIGBFB\nACgEBpmOp0h0jJgg6E9ze5Yddc1kshqyXUQkV2SCoC2TZVdDK+15CIL9+/fzve9974jfd8kll7B/\n//5Br0dE5EhEJgji4amOfDQIeguCTCbT5/see+wxRo0aNfgFiYgcgRFx1dBAxGNhEOThQTw33XQT\nb7zxBnPnziWZTJJOp6mqquLVV1/l9ddf533vex+bN2+mpaWFL3zhCyxevBg4OFzGgQMHuPjiiznn\nnHN49tlnmTx5Mo888gjFxcWDXquISHcjLgi+/qvVrNlWf9h6d6epLUtRMk4idmQdoadOquCrf9X7\n88m/9a1vsWrVKpYvX86TTz7Je97zHlatWtV16eVdd93F6NGjaW5u5q1vfSsf+MAHGDNmzCGfsW7d\nOu677z7uvPNOPvjBD/KLX/yCj3zkI0dUp4jI0RhxQdCbzqtggkdz5veKmIULFx5y/f2tt97KQw89\nBMDmzZtZt27dYUEwffp05s6dC8AZZ5zBxo0b81qjiEinERcEvf3l7u6s2lrHuPI0EyrTea2htLS0\na/nJJ5/kd7/7Hc899xwlJSWcd955PV6fX1RU1LUcj8dpbm7Oa40iIp3y1llsZmkze9HMVpjZajP7\neg/7FJnZz8xsvZm9YGY1eayHWMzy0kdQXl5OQ0NDj9vq6uqoqqqipKSEV199leeff37Qf76IyLHI\nZ4ugFTjf3Q+YWRJ4xswed/fcb8LrgH3ufqKZXQ38M3BVvgqKx4xsx+AHwZgxYzj77LOZPXs2xcXF\njB8/vmvbRRddxO23387MmTM5+eSTOfPMMwf954uIHIu8BYEHJ+MPhC+T4dT9W/gy4Gvh8oPAbWZm\n4XsHXb6CAOCnP/1pj+uLiop4/PHHe9zW2Q8wduxYVq1a1bX+i1/84qDXJyLSm7zeR2BmcTNbDuwC\nfuvuL3TbZTKwGcDdM0AdMKbbPpjZYjNbamZLa2trj7qeuOUvCEREjld5DQJ3z7r7XKAaWGhms4/y\nc+5w9wXuvmDcuB4fuTkg+WwRiIgcr4bkzmJ33w8sAS7qtmkrMAXAzBJAJbAnX3UoCEREDpfPq4bG\nmdmocLkYeBfwarfdHgU+Hi5fAfwhX/0DEAaBO3n8ESIix518XjU0EfixmcUJAucBd/+1mf0TsNTd\nHwV+CPzEzNYDe4Gr81gP8Zjh7riDRlkWEQnk86qhlcC8HtZ/JWe5BbgyXzV0d3DgOSd2hMNMiIiM\nVJEZfRTyO/DckSgrKwNg27ZtXHHFFT3uc95557F06dI+P+eWW26hqamp67WGtRaRoxHNIBgmHcaT\nJk3iwQcfPOr3dw8CDWstIkdDQTAIbrrpJr773e92vf7a177GN77xDS644ALmz5/PnDlzeOSRRw57\n38aNG5k9O7iitrm5mauvvpqZM2dy+eWXHzLW0PXXX8+CBQuYNWsWX/3qV4FgILtt27bxzne+k3e+\n851AMKz17t27Abj55puZPXs2s2fP5pZbbun6eTNnzuTTn/40s2bN4t3vfrfGNBKRkTfoHI/fBDte\n6XFT2p0ZbVmKkjGIHUEGTpgDF3+r181XXXUVN954I5/73OcAeOCBB3jiiSe44YYbqKioYPfu3Zx5\n5plceumlvT4L+Pvf/z4lJSWsXbuWlStXMn/+/K5t3/zmNxk9ejTZbJYLLriAlStXcsMNN3DzzTez\nZMkSxo4de8hnLVu2jLvvvpsXXngBd2fRokWce+65VFVVabhrETlMpFoEXd/Bg3xmaN68eezatYtt\n27axYsUKqqqqmDBhAl/60pc47bTTuPDCC9m6dSs7d+7s9TOeeuqpri/k0047jdNOO61r2wMPPMD8\n+fOZN28eq1evZs2aNX3W88wzz3D55ZdTWlpKWVkZ73//+3n66acBDXctIocbeS2CPv5yx50NW+sY\nX5FmfMXgDkV95ZVX8uCDD7Jjxw6uuuoq7r33Xmpra1m2bBnJZJKampoeh5/uz5tvvsm3v/1tXnrp\nJaqqqrj22muP6nM6abhrEekuYi0Cy9t4Q1dddRX3338/Dz74IFdeeSV1dXWccMIJJJNJlixZwqZN\nm/p8/zve8Y6ugetWrVrFypUrAaivr6e0tJTKykp27tx5yAB2vQ1//fa3v52HH36YpqYmGhsbeeih\nh3j7298+iL+tiIwkI69F0I98DTMxa9YsGhoamDx5MhMnTuTDH/4wf/VXf8WcOXNYsGABp5xySp/v\nv/766/nEJz7BzJkzmTlzJmeccQYAp59+OvPmzeOUU05hypQpnH322V3vWbx4MRdddBGTJk1iyZIl\nXevnz5/Ptddey8KFCwH41Kc+xbx583QaSER6ZMfbcAsLFizw7tfXr127lpkzZw7o/et2NpCMx6gZ\nW9r/zhF3JMdVRIY3M1vm7gt62hapU0OggedERLqLZhAcZ60gEZF8GjFBMNBTXHo4zcAcb6cMReTo\njYggSKfT7NmzZ0BfXjo11D93Z8+ePaTTg3uJrYgMTyPiqqHq6mq2bNnCQB5j2dDSTl1zhlhdute7\nfCUI1+rq6kKXISJDYEQEQTKZZPr06QPa9yfPbeT/fXQ1L/3jhYwrL+p3fxGRkW5EnBo6EhXFSQDq\nmtsLXImIyPCgIBARibjIBUFlGAT1CgIRESDKQdCiIBARgQgHgU4NiYgEIhcEFekwCJoUBCIiEMEg\nSCViFCfjahGIiIQiFwQQnB5SEIiIBCIbBOosFhEJRDYI1CIQEQlEMggqipPUNWcKXYaIyLAQ0SBI\n6IYyEZFQ3oLAzKaY2RIzW2Nmq83sCz3sc56Z1ZnZ8nD6Sr7qyaVTQyIiB+Vz9NEM8Hfu/rKZlQPL\nzOy37r6m235Pu/t781jHYSqLkxxozZDJdpCIR7JRJCLSJW/fgu6+3d1fDpcbgLXA5Hz9vCPReXdx\nQ4v6CUREhuTPYTOrAeYBL/Sw+W1mtsLMHjezWb28f7GZLTWzpQN5+Ex/NMyEiMhBeQ8CMysDfgHc\n6O713Ta/DExz99OB7wAP9/QZ7n6Huy9w9wXjxo075pq6hplQEIiI5DcIzCxJEAL3uvsvu29393p3\nPxAuPwYkzWxsPmsCqCxREIiIdMrnVUMG/BBY6+4397LPhHA/zGxhWM+efNXUSaeGREQOyudVQ2cD\nHwVeMbPl4bovAVMB3P124ArgejPLAM3A1e7ueawJ0DMJRERy5S0I3P0ZwPrZ5zbgtnzV0Bu1CERE\nDorkRfRFiRipeExBICJCRIPAzKgoTmqYCRERIhoEAJXFCbUIRESIdBAkqdcIpCIi0Q4CtQhERBQE\nhS5DRKTgIhsEFQoCEREgwkHQ+dzijo68378mIjKsRToI3OFAmzqMRSTaIhsEFZ13Fzfp9JCIRFtk\ng0DDTIiIBCIbBJ3PJNDdxSISdZENArUIREQC0Q0CPZxGRASIchDomQQiIkCEg6A0FSceM7UIRCTy\nIhsEZkZFWiOQiohENgigc7wh3VAmItGmIFCLQEQiLtJBoKeUiYhEPAgqFQQiItEOAg1FLSIS8SDo\n7CNw11DUIhJdkQ+CTIfT1JYtdCkiIgUT+SAA3V0sItGmIEDjDYlItCkI0MNpRCTa8hYEZjbFzJaY\n2RozW21mX+hhHzOzW81svZmtNLP5+aqnJ53PJFCLQESiLJHHz84Af+fuL5tZObDMzH7r7mty9rkY\nOCmcFgHfD+dDQqeGRETy2CJw9+3u/nK43ACsBSZ32+0y4B4PPA+MMrOJ+aqpu4OdxRpvSESia0j6\nCMysBpgHvNBt02Rgc87rLRweFpjZYjNbamZLa2trB62u8nQCM7UIRCTa8h4EZlYG/AK40d3rj+Yz\n3P0Od1/g7gvGjRs3aLXFYkZ5UULDTIhIpOU1CMwsSRAC97r7L3vYZSswJed1dbhuyGiYCRGJunxe\nNWTAD4G17n5zL7s9CnwsvHroTKDO3bfnq6aeaChqEYm6fF41dDbwUeAVM1servsSMBXA3W8HHgMu\nAdYDTcAn8lhPjxQEIhJ1eQsCd38GsH72ceBz+aphICqLk6zfdaCQJYiIFFSk7ywGtQhERCIfBOos\nFpGoi3wQVBYnac100NKuoahFJJoiHwQVnXcXq1UgIhE1oCAws7eYWVG4fJ6Z3WBmo/Jb2tDQMwlE\nJOoG2iL4BZA1sxOBOwhuAvtp3qoaQhp4TkSibqBB0OHuGeBy4Dvu/j+BIRscLp8q0sEVtAoCEYmq\ngQZBu5ldA3wc+HW4LpmfkoaWWgQiEnUDDYJPAG8Dvunub5rZdOAn+Str6OgpZSISdQO6szh8mMwN\nAGZWBZS7+z/ns7ChUqFnEohIxA30qqEnzazCzEYDLwN3mllvA8kdV5LxGKWpuE4NiUhkDfTUUGX4\nLIH3EzxRbBFwYf7KGloaZkJEomygQZAIHyH5QQ52Fo8YGmZCRKJsoEHwT8ATwBvu/pKZzQDW5a+s\noaUgEJEoG2hn8c+Bn+e83gB8IF9FDbXK4iSb9zYVugwRkYIYaGdxtZk9ZGa7wukXZlad7+KGSmVx\nUmMNiUhkDfTU0N0Ej5WcFE6/CteNCOosFpEoG2gQjHP3u909E04/Asblsa4hVZFO0tiWpT3bUehS\nRESG3ECDYI+ZfcTM4uH0EWBPPgsbSpXFQVeJTg+JSBQNNAg+SXDp6A5gO3AFcG2eahpylSUab0hE\nomtAQeDum9z9Uncf5+4nuPv7GGFXDYGGmRCRaDqWJ5T97aBVUWAagVREouxYgsAGrYoCq0grCEQk\nuo4lCHzQqigwtQhEJMr6vLPYzBro+QvfgOK8VFQAeoC9iERZn0Hg7uVDVUghpZNxihIxBYGIRNKx\nnBoaUXR3sYhEVd6CwMzuCsclWtXL9vPMrM7MlofTV/JVy0BoBFIRiaoBjT56lH4E3Abc08c+T7v7\ne/NYw4CpRSAiUZW3FoG7PwXszdfnDzYFgYhEVaH7CN5mZivM7HEzm9XbTma22MyWmtnS2travBRS\nWZykvkVBICLRU8ggeBmY5u6nA98BHu5tR3e/w90XuPuCcePyM+hpZXGSuiYFgYhET8GCwN3r3f1A\nuPwYkDSzsYWqp7qqmPqWDDvrWwpVgohIQRQsCMxsgplZuLwwrKVgQ1svmj4GgOc3jJjRtUVEBiRv\nVw2Z2X3AecBYM9sCfBVIArj77QRDWV9vZhmgGbja3Qs2bMWpkyooL0rwwpt7uWzu5EKVISIy5PIW\nBO5+TT/bbyO4vHRYiMeMBTVVvKAWgYhETKGvGhpWFs0Ywxu1jdQ2tBa6FBGRIaMgyLFo+mgAXnzz\nuLn9QUTkmCkIcsyeXElJKs4Lb+r0kIhEh4IgRzIe44xpVbywQS0CEYkOBUE3Z84Yw2s7G9jb2Fbo\nUkREhkR0gqB5H6x+GDqyfe6mfgIRiZroBMG638HPPw7bV/S522nVo0gnY+onEJHIiE4QTH9HMH/z\nv/vcLZVQP4GIREt0gqB8PIybCRv6DgIIhptYu6Neg9CJSCREJwgAZpwLf34eMn3fMLZo+mjc4cWN\nahWIyMgXrSCYfi5kmmHzi33udvqUUaQSMQ03ISKREK0gqDkbLNZvP0E6GWfelFG8oCuHRCQCohUE\n6UqYNH9g/QQzxrB6W52eWiYiI160ggCCfoKty6Clvs/dzpw+mg6HZRv3DVFhIiKFEb0gmH4ueBY2\nPdvnbvOmVpGMG8/rfgIRGeGiFwRTFkEi3W8/QXEqzunVo3Q/gYiMeNELgmQ6CIMB9ROM5pWtdTS2\nZoagMBGRwoheEEDQT7BrNRyo7XO3RdPHkO1wlm1SP4GIjFzRDILp5wXzfk4PnTGtinjMNO6QiIxo\n0QyCSXOhqLLfICgtSjBncqX6CURkRItmEMTiUHPOgPsJVmzZT3Nb38NXi4gcr6IZBBD0E+zfBPs2\n9rnbmdPH0J51Xv6z+glEZGSKbhBMPzeY99MqWFBTRczQuEMiMmJFNwjGnQxlE/rtJyhPJ5k1qZLn\nNe6QiIxQ0Q0Cs+BhNW8+Be597rpo+miWb95PS7v6CURk5IluEEDQT9BYC7vW9LnbohljaMt0sHzz\n/iEqTERk6OQtCMzsLjPbZWaretluZnarma03s5VmNj9ftfRqgP0EC2tGY4YuIxWRESmfLYIfARf1\nsf1i4KRwWgx8P4+19GzUFBg9o99+gsqSJDMnVPDE6h1ksh1DVJyIyNDIWxC4+1NAX39CXwbc44Hn\ngVFmNjFf9fRq+rmw8Y+Q7Xs8ob8+dwZrttfz779fN0SFiYgMjUL2EUwGNue83hKuG1ozzoW2Btj2\ncp+7XTZ3MlecUc1tS9bz7Bu7h6g4EZH8Oy46i81ssZktNbOltbV9DxR3xGreEcw3PNnvrl+/dBbT\nx5byP362nL2NbYNbh4hIgRQyCLYCU3JeV4frDuPud7j7AndfMG7cuMGtonQMTDhtQMNNlBYl+M41\n89jX2M4Xf74C7+eyUxGR40Ehg+BR4GPh1UNnAnXuvr0glcw4F7a8CG1N/e46a1IlX7rkFP7w6i7u\n+uPG/NcmIpJn+bx89D7gOeBkM9tiZteZ2WfM7DPhLo8BG4D1wJ3AZ/NVS7+mnwfZNvjzcwPa/eNn\n1XDhzPF86/G1rNpal9/aRETyLJ9XDV3j7hPdPenu1e7+Q3e/3d1vD7e7u3/O3d/i7nPcfWm+aunX\ntLdBLNnvZaSdzIx/veI0xpYV8fn7/sQBPcFMRI5jx0Vncd6lSqH6rbD+99DeMqC3VJWmuOWquWza\n08hXHunxnjkRkeOCgqDT7PfDzlXwnfmw7EeQbe/3LYtmjOGGC07ily9v5Zcvb8l/jSIieaAg6LTw\n0/CxR6B8IvzqC3DbW2HFz6Cj74HmPn/+SSyaPpovP7yKDbUHhqhYEZHBoyDINeM8+NTv4JqfQaoM\nHloM3z8L1jzS6wil8Zhxy9VzKUrEuPqO53llizqPReT4oiDozgxOvgj++im48kfgHfDAx+COc3u9\n6WxiZTH3L34byXiMD/7f5/jN6h1DWrKIyLFQEPQmFoNZl8Nnn4f33Q7N++Gey+DRG6C14bDdT55Q\nzkOfO4u/GF/GX//HMn7w9AbdcCYixwUFQX9icZh7DXzuRTjrBnj5HvjeWT3eiXxCeZr7F7+Ni2ZN\n4Bv/uZYvP7xKo5WKyLCnIBioZBre/b/gk09APAn3XAr/+UVoazxkt+JUnO9+aD6fOfct3PvCn/nk\nj5fS0NL/FUgiIoWiIDhSUxfBZ56BMz8LL/0g6Eze9Owhu8Rixk0Xn8K33j+HZ9fv5orvP8eWff0P\nXyEiUggKgqORKoGL/jdc+5/B67svgf/6ErQ3H7Lb1Qun8uNPLmRbXTPv++6zPPbKdjo61G8gIsOL\nguBY1JwNn/kjvPU6eP67cNdfQv22Q3Y5+8SxPPTZs6gqSfLZe1/mkluf5r9WKRBEZPiw4+3KlgUL\nFvjSpYUblqhXrz8BD34Sisrhmvth0txDNmc7nF+t2Matv1/Hht2NnDqxghsvPIl3nToeMytQ0SIS\nFWa2zN0X9LhNQTCIdq6Gn14FTXvg/XfCzPcetksm28GjYSBs3NPE7MkV3HjBX3DBzBMUCCKSNwqC\nodSwE+6/Bra+DO/6enDJaQ9f8JlsBw/9aSvf+cN6/ry3idOqK7nunOlcPHsiqYTO2InI4FIQDLX2\nZnj4elj9EMz7KLznZkiket4128FDL2/le0+uZ+OeJsaVF/GhhVP58KKpnFCRHuLCRWSkUhAUQkcH\nPPn/wVP/CjVvhw/eAyWj+9jd+e91tfz42Y08+VotiZhxyZyJfPysacyfWqXTRiJyTBQEhbTifnj0\n81A5Ba68Gyae3u9bNu5u5J7nNvHzpZtpaM0we3IF1yycyttmjGH62FKFgogcMQVBoW16Dh74aNCJ\nvOA6OP8fobiq37c1tmb45Z+2cs+zG1m3KxjiekxpigU1VSyYNpoFNVXMmlSpPgUR6ZeCYDho3g9L\nvhncjVw8OuhIPv1DweB2/XB31u86wNJN+1i6cR9LN+1l057gTuWiRIy5U0axaPpozj5xLPOmVikY\nROQwCoLhZPtKeOyLsPkFqF4I7/n2gE4XdbervqUrGF7auJfV2+rocChOxlk0YzTnnDiWs08cy8nj\ny4nFdCpJJOoUBMNNRwesuA9++xVo3ntEp4t6U9fczvMb9vDs+t08s343b9QGg+GNKU1x1oljWTCt\nilMnVXDKhHLK08nB+k1E5DihIBiuck8XpSth5qVwyntg+rnBaKfHYHtdM39cv4c/hsFQ29DatW3a\nmBJOnVgRTJOCaUJFWp3QIiOYgmC4274SnrkZ1v0W2g5AshTe8s4gFE76Sygdc0wf7+7srG9lzfY6\n1myrZ832etZsq2fjnoMjoo4tS3Fa9SjmTK7k9CmVzJk8inHlRcf6m4nIMKEgOF5kWmHj0/DqY/Da\n49CwDSwGU86Eky6ECafD+FlQPqHHu5WP1IHWDK9ur2f1tnpWbqlj5Zb9rK890PV45kmVaeZUV3Ja\n9ShmTizn5AkVTKpUy0HkeKQgOB65w/blQSC8+hjsfOXgtuLRQSBMmBPMx8+CsScHw2Mfo8bWDKu2\n1gXBsDUIh005LYfydIJTJpRz8oQgGE6ZUM5fnFBOZYn6HUSGMwXBSNC0F3atCQa227kqmO9aC+05\nD7wpnwSjZ8Do6cF8zFuCedV0KCo76h9d19zO6zsbeHVHA6/tqOe1HcFyQ0uma5+KdILqqhKmjC5m\nSlUJ1VXFTBldwpTRwXJJKnEsv72IHCMFwUjVkYV9G2HHK7BnHex9E/a8AXs3QOOuQ/ctPQGqasJp\nWs5yDZRPDJ7NfATcnW11Lby2o543djWyeV8Tm/c2sXlfM1v2NdHSfuizmseWpYJgCMNiatdyCRMq\n0yTjuvdBJJ8KFgRmdhHw70Ac+IG7f6vb9muBfwW2hqtuc/cf9PWZCoIBam0IgmHvBtj7RhAYnVPd\nVvDswX3jKaishlHTYNTUYKqqObhcNv6I+iTcnd0H2rrCYcu+5jAkmvjz3ia27W8h2+3BPKNKkowr\nK2JsWRFjy4uC5fIU48qKOKEizYRwqihOqI9C5CgUJAjMLA68DrwL2AK8BFzj7mty9rkWWODufzPQ\nz1UQDIJsO9RtOTQc9v8Z9m8K5o21h+6fSAdjJXW2JkZNy5nXQPGoI/rxmWwH2+tausJhZ30rtQ2t\n7D5w6LyxLXvYe9PJGOMr0ozvDIfKnHllmomVacaVFZFQC0PkEH0FQT5P3C4E1rv7hrCI+4HLgDV9\nvkvyL54M+xGm97y9rRH2bz4YDvs2hvNNsOVFaKk7dP90ZdiC6HbKqaomCJBuQ3An4rGu/oO+NLdl\nqW1oZWdDCzvqWthZH0w76lvZWdfC8s372bG6hbbMoaehYgYnlKcZX5lmYkWaiaPSTKosZuKoNBMr\ni5k0Ks0J5WniuuNaBMhvEEwGNue83gIs6mG/D5jZOwhaD//D3Td338HMFgOLAaZOnZqHUuUQqVI4\n4ZRg6knz/oMBsS8nKHathUg4lUAAAAz4SURBVNf/C7JtB/e1WNAHUTEJKiYHU+Xk8HV1MC8bD/HD\n/ykWp+JMHVPC1DG9B4a7s7+pne1hUGyva2FHXXMwr29hfe0Bnl5Xe1jrIh4zxpcHp53GlKaoKk0x\nujRFVUkq53WSUSXBuop0Qq0MGbEKfSnHr4D73L3VzP4a+DFwfved3P0O4A4ITg0NbYlymOJRwdTT\nGEkdHdCwPScoNgati/qtwdVOrz8BmeZub7LgWQ2lJ0DZuHB+ApSOC+ed68MpcfBGNzOjKvziPnVS\nRY/lujv1LRm21zWzfX8L23LmtQ2t7KhvYe32evY0ttHarXWRqzydoKokxaiSJJXFSapKUlQWJ6ko\nTlBZnOyaKoqTVKSD5VElScqK1K8hw1s+g2ArMCXndTUHO4UBcPc9OS9/APxLHuuRoRCLBX/xV06G\naWcdvt0dmvdB/bYgHOq2wIFdwVVOB8Jp61I4UAvtjT3/jKJKKB0bBsPYYCoZE06dy6O75pYq6/qS\nPmVCz2ERlOY0t2fZ29jG3sY29jS2UdfUzv6mNvY3t7M/Z3lfUzub9zZR19xOfUvmsM7vXPGYUZFO\nMKokRUVuYKQTlKTiFKcSFCfjFCdjlKQSpFNxSpJxytIJRoctlVHFSbVIJG/yGQQvASeZ2XSCALga\n+FDuDmY20d23hy8vBdbmsR4ZDiz8679kNEyY3fe+bY1hSOwOOrAbd4Xzzte1weWym18MnvXgh3cu\nBz8zBkXlQYCkK8LlimA5VQbJYkiksWQJJck0JcliqhPFwXhPJSVQkYZkSfA6WRZ0nne9LsEJ7tKu\na26nvjmYB8vtXcv7m9uoy9n25z2NNLRkaGrL0tzeS93dDltlcZLRpeGpq7BlUpFOUp5OUp5OUJ5O\nUFEcLFekk5QWJShNxSkpSlCSjGsUWulV3oLA3TNm9jfAEwSXj97l7qvN7J+Ape7+KHCDmV0KZIC9\nwLX5qkeOQ6nSvju1c7kHndhNew5OjbuD0V1b6qG1PriktnO5YTvsfi0Im/aW4Ma83oKkT4alSilP\nllCeKg2CJVWaM5UFN/OVlcLosiCEuvYrg1QlniymNVZCs6Vp8iKaKaIpAw0tmUNaJ/u6llvZuKeR\nui3tXWEyEMXJOKVFcUpSQUukoocAKU8nu9aXFSWCMCmKdy2XFSUoSsR0qmuE0Q1lIp2y7dDeHEyZ\n5pzlMCjaW7ptawrmbY3BYIFtjd2mAwfnrQego33gtXS1OooPToniHl6nycaLaCNFKymaSdHckaDJ\nkzR7kqZskqaOBI3ZBI0dCQ5k4jRkE9S1x6hvM/a1wv5W2Nvi7GuF1o4Y0PeXfDxmlKbiFKeCUClO\ndi7HSSeDeVlRoquvpLMPJVgOTomlk3EScSMVj5HsmkwBk0eFunxU5PgSTwZTuvd+hGOSaQtDoeHw\n8GhvynkdLneFT9OhAdS8L1iXaYX2ZuKZFoozLRR3ZDiyOzq6Ca/y9XgKtwQd8RTZWIqsJclakvbO\niQRtJGklRYunaG5P0tyWoqkjSVNHksaOJPWZBPsySXZlUzRRFASUp3OWi2iiiCbStJKkM3wSMSMZ\nj5GIh/Oc153LqUSs6/RXZ9B0hUy43NmC6WzZlKUTFCWO7O75KFEQiAyVRAoSYf9IPmQzQViEAUGm\nNWjNdM27LWfbg0t9O+cd7ZBtx7JtWKaNWLaNRLYt2JZpDfcNlzOt4c/ad7DV1NESrOu8fDgeTv1w\njEwsTVu8mPZYmvZYmjYros3StMVStFJEqxUFwdNRREtbigPNCRoyceozcera47yZidNKilaStIVB\n1eaJruV2EngsRaooTSxZRCyZIp5Ik0gmSScTpJMxihJx0skgaDoDJ5WIkYoHUzJcLslpDeW2jEpS\n8a5Tacdb6CgIREaKeALi5UE/RCF1ZHNOnTUFLZxDlsNWT3sztDdibU0k25tIdrWMGsPTcZ2n4OrD\nFlDLwc/tODjgITG6WjP91wa0hhPQgZEhQcYOBkabB2HS4klaSdDqCVrDda1hS6jRk+wlRUsYPi0e\nLLeEraRsLAXJNLFkMfFUmniqhGRRsJyNpSCWoiOWCFpfsRSxeNCZX5SIBZ3/YSumLGzVBC2bJCeU\nF1FVOtBfduAUBCIyuGLxoIP8GEa87VdHtocWT25rp7P10nZwuatl0w7ZVghbPalsK6lsOyWZ1mB9\ntj38nDbItuKZYF/PtOKZRrw9+BkWTrGOtp5rdKAtnPqRIUaGBO0eJ0OcLDGyxMgQp8NjZIiRJc6y\naVdw4XX/azCPJKAgEJHjUSwePH9jEJ7B0R/rNj9MR/ZgEHWeJuuc2lsOfd11iq39kOVEto1EtpV0\nNoN3ZGjPtJNp75y3k81kyGTaOeXEt+Tld1QQiIgci1j84OXCg8AIznQN/gmg3ulWRRGRiFMQiIhE\nnIJARCTiFAQiIhGnIBARiTgFgYhIxCkIREQiTkEgIhJxx90w1GZWC2w6yrePBXYPYjmDSbUdneFc\nGwzv+lTb0Tlea5vm7uN62nDcBcGxMLOlvY3HXWiq7egM59pgeNen2o7OSKxNp4ZERCJOQSAiEnFR\nC4I7Cl1AH1Tb0RnOtcHwrk+1HZ0RV1uk+ghERORwUWsRiIhINwoCEZGIi0wQmNlFZvaama03s5sK\nXU8uM9toZq+Y2XIzW1rgWu4ys11mtipn3Wgz+62ZrQvnVcOotq+Z2dbw2C03s0sKVNsUM1tiZmvM\nbLWZfSFcX/Bj10dtBT92ZpY2sxfNbEVY29fD9dPN7IXw/+vPzGwon9PSX20/MrM3c47b3KGuLafG\nuJn9ycx+Hb4+uuPm7iN+AuLAG8AMggf/rABOLXRdOfVtBMYWuo6wlncA84FVOev+BbgpXL4J+Odh\nVNvXgC8Og+M2EZgfLpcDrwOnDodj10dtBT92BA/kKguXk8ALwJnAA8DV4frbgeuHUW0/Aq4o9L+5\nsK6/BX4K/Dp8fVTHLSotgoXAenff4O5twP3AZQWuaVhy96eAvd1WXwb8OFz+MfC+IS0q1Ettw4K7\nb3f3l8PlBmAtMJlhcOz6qK3gPHAgfJkMJwfOBx4M1xfquPVW27BgZtXAe4AfhK+NozxuUQmCycDm\nnNdbGCb/EUIO/MbMlpnZ4kIX04Px7r49XN4BjC9kMT34GzNbGZ46Kshpq1xmVgPMI/gLclgdu261\nwTA4duHpjeXALuC3BK33/e6eCXcp2P/X7rW5e+dx+2Z43P6PmRUVojbgFuD/ATrC12M4yuMWlSAY\n7s5x9/nAxcDnzOwdhS6oNx60OYfNX0XA94G3AHOB7cC/FbIYMysDfgHc6O71udsKfex6qG1YHDt3\nz7r7XKCaoPV+SiHq6En32sxsNvAPBDW+FRgN/P1Q12Vm7wV2ufuywfi8qATBVmBKzuvqcN2w4O5b\nw/ku4CGC/wzDyU4zmwgQzncVuJ4u7r4z/M/aAdxJAY+dmSUJvmjvdfdfhquHxbHrqbbhdOzCevYD\nS4C3AaPMLBFuKvj/15zaLgpPtbm7twJ3U5jjdjZwqZltJDjVfT7w7xzlcYtKELwEnBT2qKeAq4FH\nC1wTAGZWamblncvAu4FVfb9ryD0KfDxc/jjwSAFrOUTnl2zocgp07MLzsz8E1rr7zTmbCn7seqtt\nOBw7MxtnZqPC5WLgXQR9GEuAK8LdCnXceqrt1ZxgN4Jz8EN+3Nz9H9y92t1rCL7P/uDuH+Zoj1uh\ne72HagIuIbha4g3gHwtdT05dMwiuYloBrC50bcB9BKcJ2gnOMV5HcO7x98A64HfA6GFU20+AV4CV\nBF+6EwtU2zkEp31WAsvD6ZLhcOz6qK3gxw44DfhTWMMq4Cvh+hnAi8B64OdA0TCq7Q/hcVsF/Afh\nlUWFmoDzOHjV0FEdNw0xISIScVE5NSQiIr1QEIiIRJyCQEQk4hQEIiIRpyAQEYk4BYFIN2aWzRlZ\ncrkN4mi1ZlaTO3qqyHCQ6H8Xkchp9mBYAZFIUItAZIAseG7Ev1jw7IgXzezEcH2Nmf0hHITs92Y2\nNVw/3sweCsezX2FmZ4UfFTezO8Mx7n8T3rUqUjAKApHDFXc7NXRVzrY6d58D3EYw+iPAd4Afu/tp\nwL3AreH6W4H/dvfTCZ6jsDpcfxLwXXefBewHPpDn30ekT7qzWKQbMzvg7mU9rN8InO/uG8JB3Ha4\n+xgz200wPEN7uH67u481s1qg2oPByTo/o4ZgOOOTwtd/DyTd/Rv5/81EeqYWgciR8V6Wj0RrznIW\n9dVJgSkIRI7MVTnz58LlZwlGgAT4MPB0uPx74HroesBJ5VAVKXIk9JeIyOGKw6dSdfovd++8hLTK\nzFYS/FV/Tbju88DdZvY/gVrgE+H6LwB3mNl1BH/5X08weqrIsKI+ApEBCvsIFrj77kLXIjKYdGpI\nRCTi1CIQEYk4tQhERCJOQSAiEnEKAhGRiFMQiIhEnIJARCTi/n9JD8HN/OGhAgAAAABJRU5ErkJg\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQuhSLW89Bqp",
        "colab_type": "code",
        "outputId": "b0879ae9-0614-4653-bcc9-78434742163d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "plt.plot(history.history[\"acc\"])\n",
        "plt.plot(history.history[\"val_acc\"])\n",
        "plt.title(\"Model Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGGM8zhKBMcZ43P8HlsuhyW4eu/IAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-K7R9QFY9Bqs",
        "colab_type": "code",
        "outputId": "84af3161-ddff-4eb9-f3fb-883b760187fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "scores = model.evaluate(X_test_mlp, Y_test, verbose=0)\n",
        "\n",
        "print(\"[INFO] test score - {}\".format(scores[0]))\n",
        "\n",
        "print(\"[INFO] test accuracy - {}\".format(scores[1]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] test score - 0.3945424437046051\n",
            "[INFO] test accuracy - 0.8582\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqXPNnes9Bqy",
        "colab_type": "text"
      },
      "source": [
        "# What are CNNs?\n",
        "\n",
        "<br />\n",
        "\n",
        "* How are images represented again?\n",
        "\n",
        "<br />\n",
        "\n",
        "![](img/image_representation.gif)\n",
        "\n",
        "<br />\n",
        "\n",
        "* What is a CNN?\n",
        "\n",
        "![](img/lecun_net.png)\n",
        "\n",
        "<br />\n",
        "\n",
        "* The four main operations in a CNN:\n",
        "\n",
        "    * Convolution\n",
        "    * Non Linearity (ReLU)\n",
        "    * Pooling or Sub Sampling\n",
        "    * Classification (Fully Connected Layer)\n",
        "\n",
        "<br />\n",
        "\n",
        "* Some important convolving operations used in ML based image classifiers, before deep learning\n",
        "\n",
        "<br />\n",
        "\n",
        "![](img/prior_convolving_operations.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QaCHdFVR9Bq0",
        "colab_type": "text"
      },
      "source": [
        "## Understanding Convolutions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCkUHRct9Bq1",
        "colab_type": "text"
      },
      "source": [
        "![](img/convolutions.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buEv8gjw9Bq2",
        "colab_type": "text"
      },
      "source": [
        "![](img/convolution_matrix.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYshLjvx9Bq3",
        "colab_type": "text"
      },
      "source": [
        "![](img/convolution_real_image.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41VtIkEH9Bq4",
        "colab_type": "text"
      },
      "source": [
        "### Output Feature Map Dimensions after Convolving"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0C6W8mI9Bq5",
        "colab_type": "text"
      },
      "source": [
        "![](img/conv_output_feature_map_formula.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7rU5pzx9Bq6",
        "colab_type": "text"
      },
      "source": [
        "        W - Width of the input feature map\n",
        "        \n",
        "        K - Width of the Kernel / Filter\n",
        "        \n",
        "        P - Padding Layer dimension\n",
        "        \n",
        "        S - Stride"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQuS1Gq49Bq8",
        "colab_type": "text"
      },
      "source": [
        "### Zero Padding in Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmaO-T569Bq-",
        "colab_type": "text"
      },
      "source": [
        "  In Keras we have two types of Padding:\n",
        "    \n",
        "      (i) Valid Padding : Any layer that does not fully intersect with the filter is ignored (NO PADDING!)\n",
        "        \n",
        "      (ii) Same Padding : Adds Zero Padding such that the output feature map has similar dimensions to the input                      feature map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Jx3V_eP9Bq_",
        "colab_type": "text"
      },
      "source": [
        "![](img/zero_padding.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLixzYzA9BrC",
        "colab_type": "text"
      },
      "source": [
        "![](img/same_padding.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqY4yDWS9BrD",
        "colab_type": "text"
      },
      "source": [
        "## CNN for MNIST Digit Recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IC5miFRy9BrD",
        "colab_type": "text"
      },
      "source": [
        "#### Preprocess input data for Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjL4RNDW9BrE",
        "colab_type": "code",
        "outputId": "ba6d9809-500c-41be-b1d2-d5cce50e9244",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print (X_train.shape[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fn1AcRg9BrG",
        "colab_type": "text"
      },
      "source": [
        "Reshape input data\n",
        "\n",
        "    When using the tensorflow backend, you must explicitly declare a dimension for the depth of the input image. \n",
        "    E.g. a full-color image with all 3 RGB channels will have a depth of 3.\n",
        "\n",
        "    Our MNIST images only have a depth of 1, but we must explicitly declare that. \n",
        "\n",
        "    In other words, we want to transform our dataset from having shape (n, width, height) to (n, width, height, channel)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_wf35PP9BrH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_cnn = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
        "X_test_cnn = X_test.reshape(X_test.shape[0], 28, 28, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "KA2jLW_i9BrL",
        "colab_type": "text"
      },
      "source": [
        " print X_train's dimensions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwFQB2PA9BrM",
        "colab_type": "code",
        "outputId": "3cb4636a-1c47-443a-ff15-041cc8952cac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print (X_train.shape)\n",
        "print (X_train_cnn.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(60000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AXeSRoM9BrS",
        "colab_type": "text"
      },
      "source": [
        "#### Define model architecture."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBQ8fR_89BrT",
        "colab_type": "text"
      },
      "source": [
        "Declaring a sequential model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmJRQ0Dh9BrT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn_model = Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2HPc9bA9BrX",
        "colab_type": "text"
      },
      "source": [
        "Declare the input layer\n",
        "\n",
        "CNN input layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BQA39du9BrX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers.convolutional import Conv2D"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPcb0Sgz9Brb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn_model.add(Conv2D(filters = 64, kernel_size = (3, 3), strides = (1,1), activation='relu', input_shape=(28,28,1)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "z_rg97gu9Brf",
        "colab_type": "text"
      },
      "source": [
        "###### 2D convolution layer (e.g. spatial convolution over images).\n",
        "\n",
        "This layer creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs. If use_bias is True, a bias vector is created and added to the outputs. Finally, if activation is not None, it is applied to the outputs as well.\n",
        "\n",
        "When using this layer as the first layer in a model, provide the keyword argument input_shape (tuple of integers, does not include the sample axis), e.g. input_shape=(28, 28, 1) for 28x28 gray pictures in data_format=\"channels_last\".\n",
        "\n",
        "First parameters correspond to the number of convolution filters \n",
        "\n",
        "Next 2 parameters correspond to kernal size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JL6XZsdN9Brh",
        "colab_type": "text"
      },
      "source": [
        "###### Add more layers to our model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nzfdPLH9Brk",
        "colab_type": "text"
      },
      "source": [
        "![](img/max_pooling.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBoOF8_C9Brl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers.pooling import MaxPooling2D"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_b2VMVuY9Brn",
        "colab_type": "code",
        "outputId": "33d5379a-72b5-4422-c587-2d6b48eda877",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "cnn_model.add(Conv2D(filters = 32, kernel_size = (3, 3), strides = (1,1), activation='relu'))\n",
        "cnn_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "cnn_model.add(Dropout(0.25))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VJke3Mx9Brx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn_model.add(Conv2D(filters = 64, kernel_size = (3, 3), strides = (1,1), activation='relu'))\n",
        "cnn_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "cnn_model.add(Dropout(0.25))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_zXLhCQ9Br1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn_model.add(Conv2D(filters = 32, kernel_size = (3, 3), strides = (1,1), activation='relu'))\n",
        "cnn_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "cnn_model.add(Dropout(0.25))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iv-UVrEC9Br3",
        "colab_type": "text"
      },
      "source": [
        "Dropout\n",
        "\n",
        "    This is a method for regularizing our model in order to prevent overfitting. \n",
        "\n",
        "MaxPooling2D \n",
        "\n",
        "    Is a way to reduce the number of parameters in our model by sliding a 2x2 pooling filter across the previous layer and taking the max of the 4 values in the 2x2 filter.\n",
        "\n",
        "So far, for model parameters, we've added two Convolution layers. To complete our model architecture, let's add a fully connected layer and then the output layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yk_WbbqA9Br4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers.core import Flatten"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpnkUcR59Br7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn_model.add(Flatten())\n",
        "cnn_model.add(BatchNormalization())\n",
        "cnn_model.add(Dense(128, activation='relu'))\n",
        "cnn_model.add(Dropout(0.5))\n",
        "cnn_model.add(BatchNormalization())\n",
        "cnn_model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UkOhKer9Br9",
        "colab_type": "text"
      },
      "source": [
        "For Dense layers, the first parameter is the output size of the layer. Keras automatically handles the connections between layers.\n",
        "\n",
        "Note that the final layer has an output size of 10, corresponding to the 10 classes of digits.\n",
        "\n",
        "Also note that the weights from the Convolution layers must be flattened (made 1-dimensional) before passing them to the fully connected Dense layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGo_MC-Q9Br9",
        "colab_type": "text"
      },
      "source": [
        "#### Compile model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nokMAIAI9Br-",
        "colab_type": "text"
      },
      "source": [
        "Compile the model by providing the loss function and the optimizer "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyFkFpug9BsA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import Adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9Gvuhr39BsE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "custom_adam = Adam(lr = 0.01, decay = 0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Sz1dLO69BsN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn_model.compile(loss = 'categorical_crossentropy', optimizer = custom_adam, metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfjQNR7a9Bsa",
        "colab_type": "code",
        "outputId": "8b12d01d-f82e-481f-da07-4cc518ee9167",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "cnn_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 64)        640       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 32)        18464     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 10, 10, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 3, 3, 32)          18464     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 1, 1, 32)          0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 1, 1, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 32)                128       \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 128)               4224      \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 62,218\n",
            "Trainable params: 61,898\n",
            "Non-trainable params: 320\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdS9hiCO9Bse",
        "colab_type": "text"
      },
      "source": [
        "#### Fit model on training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "hAnwjkQF9Bsf",
        "colab_type": "code",
        "outputId": "f5b8a0cc-45cf-4753-ad1b-d0c6c698ab43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "cnn_model.fit(X_train_cnn, Y_train, batch_size = 4096, epochs = 40, validation_split = 0.2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/40\n",
            "48000/48000 [==============================] - 8s 172us/step - loss: 1.7949 - acc: 0.3546 - val_loss: 0.9996 - val_acc: 0.6064\n",
            "Epoch 2/40\n",
            "48000/48000 [==============================] - 1s 27us/step - loss: 1.0612 - acc: 0.5878 - val_loss: 0.9265 - val_acc: 0.6178\n",
            "Epoch 3/40\n",
            "48000/48000 [==============================] - 1s 27us/step - loss: 0.8743 - acc: 0.6745 - val_loss: 0.7194 - val_acc: 0.7274\n",
            "Epoch 4/40\n",
            "48000/48000 [==============================] - 1s 27us/step - loss: 0.7783 - acc: 0.7063 - val_loss: 0.6796 - val_acc: 0.7404\n",
            "Epoch 5/40\n",
            "48000/48000 [==============================] - 1s 27us/step - loss: 0.7153 - acc: 0.7322 - val_loss: 0.6475 - val_acc: 0.7553\n",
            "Epoch 6/40\n",
            "48000/48000 [==============================] - 1s 27us/step - loss: 0.6667 - acc: 0.7513 - val_loss: 0.6188 - val_acc: 0.7682\n",
            "Epoch 7/40\n",
            "48000/48000 [==============================] - 1s 27us/step - loss: 0.6446 - acc: 0.7569 - val_loss: 0.6789 - val_acc: 0.7547\n",
            "Epoch 8/40\n",
            "48000/48000 [==============================] - 1s 27us/step - loss: 0.6158 - acc: 0.7708 - val_loss: 0.5747 - val_acc: 0.7912\n",
            "Epoch 9/40\n",
            "48000/48000 [==============================] - 1s 27us/step - loss: 0.5923 - acc: 0.7798 - val_loss: 0.5948 - val_acc: 0.7888\n",
            "Epoch 10/40\n",
            "48000/48000 [==============================] - 1s 27us/step - loss: 0.5758 - acc: 0.7859 - val_loss: 0.6630 - val_acc: 0.7564\n",
            "Epoch 11/40\n",
            "48000/48000 [==============================] - 1s 27us/step - loss: 0.5615 - acc: 0.7937 - val_loss: 0.6693 - val_acc: 0.7533\n",
            "Epoch 12/40\n",
            "48000/48000 [==============================] - 1s 27us/step - loss: 0.5481 - acc: 0.7968 - val_loss: 0.5732 - val_acc: 0.7918\n",
            "Epoch 13/40\n",
            "48000/48000 [==============================] - 1s 27us/step - loss: 0.5318 - acc: 0.8062 - val_loss: 0.5918 - val_acc: 0.7998\n",
            "Epoch 14/40\n",
            "48000/48000 [==============================] - 1s 27us/step - loss: 0.5230 - acc: 0.8097 - val_loss: 0.5295 - val_acc: 0.8283\n",
            "Epoch 15/40\n",
            "48000/48000 [==============================] - 1s 27us/step - loss: 0.5112 - acc: 0.8131 - val_loss: 0.5261 - val_acc: 0.8378\n",
            "Epoch 16/40\n",
            "48000/48000 [==============================] - 1s 27us/step - loss: 0.4987 - acc: 0.8185 - val_loss: 0.5023 - val_acc: 0.8430\n",
            "Epoch 17/40\n",
            "48000/48000 [==============================] - 1s 27us/step - loss: 0.4879 - acc: 0.8237 - val_loss: 0.5059 - val_acc: 0.8419\n",
            "Epoch 18/40\n",
            "48000/48000 [==============================] - 1s 27us/step - loss: 0.4794 - acc: 0.8264 - val_loss: 0.5041 - val_acc: 0.8473\n",
            "Epoch 19/40\n",
            "48000/48000 [==============================] - 1s 27us/step - loss: 0.4818 - acc: 0.8246 - val_loss: 0.4874 - val_acc: 0.8458\n",
            "Epoch 20/40\n",
            "48000/48000 [==============================] - 1s 27us/step - loss: 0.4746 - acc: 0.8246 - val_loss: 0.4780 - val_acc: 0.8562\n",
            "Epoch 21/40\n",
            "48000/48000 [==============================] - 1s 27us/step - loss: 0.4687 - acc: 0.8300 - val_loss: 0.4871 - val_acc: 0.8526\n",
            "Epoch 22/40\n",
            "48000/48000 [==============================] - 1s 27us/step - loss: 0.4563 - acc: 0.8368 - val_loss: 0.4927 - val_acc: 0.8466\n",
            "Epoch 23/40\n",
            "48000/48000 [==============================] - 1s 27us/step - loss: 0.4550 - acc: 0.8351 - val_loss: 0.4853 - val_acc: 0.8547\n",
            "Epoch 24/40\n",
            "48000/48000 [==============================] - 1s 27us/step - loss: 0.4491 - acc: 0.8378 - val_loss: 0.4587 - val_acc: 0.8646\n",
            "Epoch 25/40\n",
            "48000/48000 [==============================] - 1s 27us/step - loss: 0.4434 - acc: 0.8407 - val_loss: 0.4711 - val_acc: 0.8638\n",
            "Epoch 26/40\n",
            "48000/48000 [==============================] - 1s 27us/step - loss: 0.4393 - acc: 0.8407 - val_loss: 0.4540 - val_acc: 0.8673\n",
            "Epoch 27/40\n",
            "48000/48000 [==============================] - 1s 27us/step - loss: 0.4348 - acc: 0.8424 - val_loss: 0.4457 - val_acc: 0.8678\n",
            "Epoch 28/40\n",
            "48000/48000 [==============================] - 1s 27us/step - loss: 0.4279 - acc: 0.8466 - val_loss: 0.4414 - val_acc: 0.8697\n",
            "Epoch 29/40\n",
            "48000/48000 [==============================] - 1s 27us/step - loss: 0.4278 - acc: 0.8480 - val_loss: 0.4153 - val_acc: 0.8722\n",
            "Epoch 30/40\n",
            "48000/48000 [==============================] - 1s 27us/step - loss: 0.4254 - acc: 0.8470 - val_loss: 0.4330 - val_acc: 0.8703\n",
            "Epoch 31/40\n",
            "48000/48000 [==============================] - 1s 27us/step - loss: 0.4232 - acc: 0.8485 - val_loss: 0.4120 - val_acc: 0.8723\n",
            "Epoch 32/40\n",
            "48000/48000 [==============================] - 1s 27us/step - loss: 0.4202 - acc: 0.8492 - val_loss: 0.3950 - val_acc: 0.8750\n",
            "Epoch 33/40\n",
            "48000/48000 [==============================] - 1s 27us/step - loss: 0.4103 - acc: 0.8533 - val_loss: 0.3891 - val_acc: 0.8789\n",
            "Epoch 34/40\n",
            "48000/48000 [==============================] - 1s 27us/step - loss: 0.4148 - acc: 0.8519 - val_loss: 0.3949 - val_acc: 0.8724\n",
            "Epoch 35/40\n",
            "48000/48000 [==============================] - 1s 27us/step - loss: 0.4090 - acc: 0.8534 - val_loss: 0.3775 - val_acc: 0.8783\n",
            "Epoch 36/40\n",
            "48000/48000 [==============================] - 1s 27us/step - loss: 0.4056 - acc: 0.8553 - val_loss: 0.3846 - val_acc: 0.8745\n",
            "Epoch 37/40\n",
            "48000/48000 [==============================] - 1s 27us/step - loss: 0.4037 - acc: 0.8550 - val_loss: 0.3725 - val_acc: 0.8766\n",
            "Epoch 38/40\n",
            "48000/48000 [==============================] - 1s 27us/step - loss: 0.4055 - acc: 0.8555 - val_loss: 0.3670 - val_acc: 0.8824\n",
            "Epoch 39/40\n",
            "48000/48000 [==============================] - 1s 27us/step - loss: 0.3987 - acc: 0.8584 - val_loss: 0.3624 - val_acc: 0.8812\n",
            "Epoch 40/40\n",
            "48000/48000 [==============================] - 1s 27us/step - loss: 0.3974 - acc: 0.8603 - val_loss: 0.3537 - val_acc: 0.8839\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3caa0f02e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7n44A1Y9Bsm",
        "colab_type": "text"
      },
      "source": [
        "#### Evaluate the model on test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PBwJN6K9Bsn",
        "colab_type": "code",
        "outputId": "cea7ccc7-6d37-434c-c935-700ca50e47a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "score = cnn_model.evaluate(X_test_cnn, Y_test)\n",
        "\n",
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 92us/step\n",
            "[0.36018063666820527, 0.8799]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ps4u2L-9Bsq",
        "colab_type": "text"
      },
      "source": [
        "#### Make predictions on test data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZcz-tTc9Bsr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate predictions\n",
        "predictions = cnn_model.predict(X_test_cnn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVeOJhWR9Bsu",
        "colab_type": "code",
        "outputId": "2f5c1fa5-d5de-4b31-e764-5e031470b8bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "print (predictions)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3.51519302e-05 2.28195458e-05 4.39325640e-06 ... 2.02877466e-02\n",
            "  4.17247247e-05 9.71505821e-01]\n",
            " [2.11025290e-02 3.01592430e-04 7.84454286e-01 ... 1.56773567e-05\n",
            "  2.63804896e-03 1.26848490e-05]\n",
            " [1.27264602e-05 9.99860287e-01 3.48501567e-06 ... 1.95554488e-08\n",
            "  4.96183588e-07 1.96147153e-06]\n",
            " ...\n",
            " [1.00987876e-04 3.00309239e-06 8.62599700e-05 ... 1.28742293e-04\n",
            "  9.98743832e-01 3.23215409e-06]\n",
            " [2.80859258e-05 9.99690056e-01 6.29264696e-06 ... 4.66087080e-08\n",
            "  1.27220903e-06 3.05675576e-06]\n",
            " [5.96238952e-03 1.52971677e-03 4.98809991e-03 ... 1.84271276e-01\n",
            "  1.21921420e-01 1.28180217e-02]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PMx5SL09Bsv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred_class = cnn_model.predict_classes(X_test_cnn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVMtyvKk9Bsx",
        "colab_type": "code",
        "outputId": "4e196516-400a-4b9a-fd16-165b31fe546e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# calculate accuracy of class predictions\n",
        "from sklearn import metrics\n",
        "metrics.accuracy_score(y_test, y_pred_class)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8799"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "5R2i16TX9Bs2",
        "colab_type": "code",
        "outputId": "4f84acb8-3967-48d9-89f1-96081a77e339",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# print the confusion matrix\n",
        "metrics.confusion_matrix(y_test, y_pred_class)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[891,   0,  25,  19,   1,   0,  51,   0,  13,   0],\n",
              "       [  3, 966,   0,  24,   1,   0,   4,   0,   2,   0],\n",
              "       [ 14,   0, 879,   7,  46,   0,  48,   0,   6,   0],\n",
              "       [ 28,   1,  25, 894,  19,   0,  32,   0,   1,   0],\n",
              "       [  0,   0,  62,  39, 773,   0, 123,   0,   3,   0],\n",
              "       [  0,   0,   0,   2,   0, 956,   0,  23,   2,  17],\n",
              "       [206,   0, 101,  27, 103,   0, 543,   0,  20,   0],\n",
              "       [  0,   0,   0,   0,   0,  11,   0, 943,   1,  45],\n",
              "       [  1,   0,   1,   4,   1,   4,   4,   0, 985,   0],\n",
              "       [  0,   0,   0,   0,   0,   6,   0,  25,   0, 969]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRDPIFZU9Bs5",
        "colab_type": "text"
      },
      "source": [
        "Reference: \n",
        "\n",
        "    https://keras.io/\n",
        "    https://elitedatascience.com\n",
        "    http://scikit-learn.org/stable/modules/classes.html"
      ]
    }
  ]
}